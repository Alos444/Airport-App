{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from load_data.ipynb\n",
      "importing Jupyter notebook from Null_Handling.ipynb\n",
      "importing Jupyter notebook from Visualize.ipynb\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "from tkinter import filedialog\n",
    "# which is used to save file in any extension\n",
    "from tkinter.filedialog import asksaveasfile\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from PIL import Image, ImageTk\n",
    "from tkinter.filedialog import askopenfile\n",
    "from tkinter.font import Font\n",
    "import import_ipynb\n",
    "from pandastable import Table, TableModel,config\n",
    "from tkintertable import TableCanvas\n",
    "import os\n",
    "import missingno as msno\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "import seaborn as sns\n",
    "import load_data \n",
    "import Null_Handling\n",
    "import Visualize\n",
    "\n",
    "class Manipulate_data:\n",
    "    \n",
    "\n",
    "\n",
    "    def convert_csv_to_json(self,parent):\n",
    "        \n",
    "        '''\n",
    "        csv_file_path = filedialog.askopenfilename(initialdir = '/Desktop',\n",
    "                                                    title = 'Select a CSV file',\n",
    "                                                    filetypes = (('csv file','*.csv'),\n",
    "                                                                 ('csv file','*.csv')))\n",
    "        '''\n",
    "        \n",
    "\n",
    "        #create a dictionary\n",
    "        jsonArray = []\n",
    "        list1 = parent.csv_file_pathOriginal.split(\"/\") #Path of the viewed csv file\n",
    "        path_name=list1[-1] #actual name of the vieved csv file\n",
    "  \n",
    "        list2 = list1[:-1]  #remove the name of the csv and extract only the file path\n",
    "        list2.append('JSON') #append the file path list with a new directory JSON\n",
    "        joined_path_list2 = \"\\\\\".join(list2) # Generate the file path\n",
    "        \n",
    "        list2.append(path_name) # Again append the path with file name, so user do not need to manually type the name to save\n",
    "        joined_path_list3 = \"\\\\\".join(list2)\n",
    "        joined_path=joined_path_list3.replace(\".csv\",\"\") #\n",
    "        print(joined_path)\n",
    "        \n",
    "        # Create directory. This directory is to save json objects, and the objects will be saved here\n",
    "        dirName = joined_path_list2\n",
    "        try:\n",
    "            # Create target Directory\n",
    "            os.mkdir(dirName)\n",
    "            print(\"Directory \" , dirName ,  \" Created \") \n",
    "        except FileExistsError:\n",
    "            print(\"Directory \" , dirName ,  \" already exists\")\n",
    "            \n",
    "\n",
    "        #Step 2\n",
    "        #open a csv file handler\n",
    "        with open(parent.csv_file_pathOriginal, encoding = 'utf-8') as csv_file_handler:\n",
    "            csv_reader = csv.DictReader(csv_file_handler)\n",
    "\n",
    "            #convert each row into a dictionary\n",
    "            #and add the converted data to the data_variable\n",
    "\n",
    "            for rows in csv_reader:\n",
    "                jsonArray.append(rows)\n",
    "\n",
    "\n",
    "        #open a json file handler and use json.dumps\n",
    "        #method to dump the data\n",
    "        #Step 3\n",
    "        \n",
    "        files = [('JSON Files', '*.json')]\n",
    "        json_file_path = asksaveasfile(filetypes = files, defaultextension = files, initialfile=joined_path)\n",
    "        \n",
    "        \n",
    "        with open(json_file_path.name, 'w', encoding = 'utf-8') as json_file_handler:\n",
    "            #Step 4\n",
    "            json_file_handler.write(json.dumps(jsonArray, indent = 4))\n",
    "            \n",
    "\n",
    "    # This method is to load and display the files into application\n",
    "    def display_file(self,parent,frame1,frame2,title, file_type):\n",
    "        try:\n",
    "\n",
    "            parent.df,parent.df2,parent.list2,parent.csv_file_pathOriginal= Visualize.Display().return_dataframe(title, file_type)\n",
    "            \n",
    "       \n",
    "            \n",
    "            if (len(parent.df)== 0):\n",
    "                msg.showinfo('No records', 'No records')\n",
    "            \n",
    "            parent.height_df = 0\n",
    "            parent.width_df = 0\n",
    "            parent.place_df_x = 0\n",
    "            parent.place_df_y = 0\n",
    "                \n",
    "            # This is to save csv as json\n",
    "            # This is where the dataframe is displayed\n",
    "            if(parent.type == 'csv'):\n",
    "                parent.convert_button.place(relx=0.1,rely=0.8) \n",
    "                # Window where dataframe needs to be placed\n",
    "                main_place = parent\n",
    "                main_place.height_df = 400\n",
    "                main_place.width_df = 650\n",
    "                main_place.place_df_x = 0.1\n",
    "                main_place.place_df_y = 0.2\n",
    "                Visualize.Display.display_dataframe_tables(self,main_place,parent.df,parent)\n",
    "                \n",
    "                # print file name\n",
    "                parent.fileNameLabel.configure(text=parent.list2[-1])\n",
    "                parent.fileNameLabel.place(relx=0.1,rely=0.24)\n",
    "            else:\n",
    "                \n",
    "                main_place = frame2\n",
    "                main_place.height_df = 310\n",
    "                main_place.width_df = 600\n",
    "                main_place.place_df_x = 0.04\n",
    "                main_place.place_df_y = 0.05\n",
    "                \n",
    "                # display null values graph\n",
    "                Null_Handling.Null_Values_Handling().null_values_display_graph(main_place,parent.df)\n",
    "                \n",
    "                # Main table display to preprocess\n",
    "                main_place = frame1\n",
    "                main_place.height_df = 280\n",
    "                main_place.width_df = 660\n",
    "                main_place.place_df_x = 0.04\n",
    "                main_place.place_df_y = 0.06\n",
    "                \n",
    "                # Display Main table from json files\n",
    "                Visualize.Display.display_dataframe_tables(self,main_place,parent.df,frame1)\n",
    "\n",
    "                # Display the statistical Description dataframe\n",
    "                parent.message_label2.place(relx=0.04,rely=0.55)\n",
    "                \n",
    "                main_place.height_df = 230\n",
    "                main_place.width_df = 550\n",
    "                main_place.place_df_x = 0.04\n",
    "                main_place.place_df_y = 0.6\n",
    "                \n",
    "                #Display  the statistical description\n",
    "                Visualize.Display.display_dataframe_tables(self,main_place,parent.df2,frame1)\n",
    "                \n",
    "                # Get Null columns of the values\n",
    "                columns = Null_Handling.Null_Values_Handling().get_null_columns(parent.df)\n",
    "\n",
    "                # Print file name of the main dataframe\n",
    "                parent.fileNameLabel.configure(text=parent.list2[-1])\n",
    "                parent.fileNameLabel.place(relx=0.1,rely=0.01) \n",
    "                \n",
    "                # Null visualization display\n",
    "                parent.null_display.configure(text='Handle Null values and outliers : {}'.format(parent.list2[-1]))\n",
    "                \n",
    "                # Display columns which contains nulls - Dataframe 2 of Preprocess - Checkboxes\n",
    "                \n",
    "                \n",
    "                # Display check boxes for fifferent columns\n",
    "                if (len(parent.check_box_list)==0):  # add checkbutton)\n",
    "                    Null_Handling.Null_Values_Handling().check_box_create(parent,columns,frame2,0.1,0.62)\n",
    "                else:\n",
    "                    for i in parent.check_box_list:\n",
    "                        i.pack_forget()\n",
    "                    parent.text_box_list.pack_forget()\n",
    "                        \n",
    "                    Null_Handling.Null_Values_Handling().check_box_create(parent,columns,frame2,0.1,0.62)\n",
    "\n",
    "          \n",
    "        except FileNotFoundError as e:\n",
    "            print(e)\n",
    "            msg.showerror('Error in opening file',e)\n",
    "\n",
    "    def handle_airport_data(self,parent,main_place,place,title, file_type ):\n",
    "        \n",
    "        # parent.airport_df holds data of airpots\n",
    "        parent.airport_df,parent.df2,parent.file_path_list,parent.csv_file_pathOriginal = Visualize.Display().return_dataframe(title, file_type)\n",
    "        \n",
    "        Visualize.Display.display_dataframe_tables(self,main_place,parent.airport_df,place)\n",
    "        \n",
    "        self.airport_types = tk.Label(parent.extra_frame1,\n",
    "           text = 'Select actions to be performed for the airport dataset',\n",
    "           font = ('Arial', 12,'bold'),\n",
    "           fg = '#000000',\n",
    "           bg='#FFFFF0')\n",
    "        \n",
    "        self.airport_types.place(relx=0.05,rely=0.49)\n",
    "        parent.w.pack()\n",
    "        parent.w.place(relx=0.6,rely=0.49)\n",
    "        \n",
    "\n",
    "    def save_dataframe_as_json(self,parent):\n",
    "\n",
    "        new_fname=self.file_name(parent)\n",
    "        \n",
    "        files = [('JSON Files', '*.json')]\n",
    "        json_file_path = asksaveasfile(filetypes = files, defaultextension = files, initialfile=new_fname)\n",
    "        parent.df.to_json (json_file_path.name)        \n",
    "        \n",
    "\n",
    "    def file_name(self,parent):\n",
    "        #print(parent.csv_file_pathOriginal)\n",
    "        list1 = parent.csv_file_pathOriginal.split(\"/\") #Path of the viewed csv file\n",
    "        file_name=list1[-1] #actual name of the vieved json file\n",
    "        list2 = list1[:-1]  #remove the name of the json and extract only the file path\n",
    "        #list2.append('JSON') #append the file path list with a new directory JSON\n",
    "        list2.append(file_name) # Again append the path with file name, so user do not need to manually type the name to save\n",
    "        joined_path_list2 = \"\\\\\".join(list2) # Generate the file path\n",
    "\n",
    "        #if not os.path.exists(joined_path_list2):\n",
    "        #    return(joined_path_list2)\n",
    "        filename, file_extension = os.path.splitext(joined_path_list2)\n",
    "        print(filename, 'hhhh',filename[-1])\n",
    "        i = 1\n",
    "        if (filename[-1].isnumeric()):\n",
    "            new_fname = \"{}-{}{}\".format(filename[:-2], i, file_extension)\n",
    "            while os.path.exists(new_fname):\n",
    "                i += 1\n",
    "                new_fname = \"{}-{}{}\".format(filename[:-2], i, file_extension)\n",
    "            return(new_fname)\n",
    "        else:\n",
    "            new_fname = \"{}-{}{}\".format(filename, i, file_extension)\n",
    "            return(new_fname)\n",
    "        \n",
    "    def find_unique_types(self,dataframe,column):\n",
    "        return(dataframe[column].unique())\n",
    "        \n",
    "        \n",
    "    def merge_airport_frequencie(self,parent,main_place,extra_frame2, title, file_types):\n",
    "        \n",
    "        self.main_place = self\n",
    "        self.main_place.height_df = 250\n",
    "        self.main_place.width_df = 700\n",
    "        self.main_place.place_df_x = 0.05\n",
    "        self.main_place.place_df_y = 0.07\n",
    "        \n",
    "        # This is to load the airport frequencies dataframe\n",
    "        airport_freq_df,df2,parent.list2,parent.csv_file_pathOriginal=Visualize.Display().return_dataframe(title, file_types)\n",
    "        \n",
    "        \n",
    "        # Now merging airport and frequencies dataframes\n",
    "        parent.merged_df = pd.merge(airport_freq_df,parent.airport_df,left_on=['airport_ref','airport_ident'], right_on=['id','ident'])\n",
    "        \n",
    "        # Get airport types and country types unique columns. These values were fetched here to load airport types for statistics tab\n",
    "        parent.airport_types = self.find_unique_types(parent.merged_df,'type_y')\n",
    "        \n",
    "        parent.country_types = self.find_unique_types(parent.merged_df,'iso_country') \n",
    "        \n",
    "        parent.merge_label.place(relx=0.1,rely=0.5)\n",
    "        parent.filter_merged.place(relx=0.5,rely=0.5)\n",
    "        \n",
    "        Visualize.Display.display_dataframe_tables(self,self.main_place,parent.merged_df,parent.extra_frame2)\n",
    "        \n",
    "        Null_Handling.Null_Values_Handling().check_box_create(parent,parent.airport_types,parent.extra_frame3,0.05,0.15)\n",
    "        \n",
    "        Null_Handling.Null_Values_Handling().check_box_create(parent,parent.airport_types,parent.extra_frame4,0.05,0.15)\n",
    "        \n",
    "        parent.freq.place(relx=0.5,rely=0.15)\n",
    "        \n",
    "        \n",
    "    def merge_airport_data(self,parent):\n",
    "        \n",
    "        selected_checkboxes=Null_Handling.Null_Values_Handling().return_selected_checkboxes(parent,parent.null_cols)\n",
    "        \n",
    "        if (parent.type ==\"airport\"):\n",
    "            parent.rec = parent.merged_df.loc[parent.merged_df['type_y'].isin(selected_checkboxes)]\n",
    "            \n",
    "        if (parent.type ==\"country\"):\n",
    "            parent.rec = parent.merged_df.loc[parent.merged_df['iso_country'].isin(selected_checkboxes)]\n",
    "        #print(rec)\n",
    "        \n",
    "        Visualize.Display.display_dataframe_tables(self,parent.main_place,parent.rec,parent.extra_frame2)\n",
    "\n",
    "\n",
    "    def correlation_dataa(self,parent):\n",
    "\n",
    "        # Group the data by country and the types of the airport and extract country, airport type and the communication frequency\n",
    "        group_data = parent.merged_df.groupby(['iso_country','type_y'], as_index=False).mean() #mean function\n",
    "        group_data2 = group_data[['iso_country','type_y','frequency_mhz']]\n",
    "        \n",
    "        print(group_data2)\n",
    "        \n",
    "        # Pivot the dataframe by valyes in airport type and fill the dataframe by each airport type \n",
    "        group_data3 = group_data2.pivot(index='iso_country', columns='type_y')['frequency_mhz']\n",
    "        group_data3 = group_data3[['small_airport','medium_airport','large_airport']]\n",
    "        print(group_data3)\n",
    "        \n",
    "        #find the correlation of the dataframe\n",
    "        corr = group_data3.corr()\n",
    "        print(corr)\n",
    "\n",
    "        import seaborn as sns\n",
    "\n",
    "        # Print the correlation heatmap in the application\n",
    "        f, ax = plt.subplots(figsize=(10, 8))\n",
    "        corr = group_data3.corr()\n",
    "        sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "                    square=True, ax=ax, annot=True)\n",
    "        plt.show()\n",
    "        \n",
    "        self.bargra = tk.LabelFrame(parent.extra_frame5) \n",
    "        self.bargra.place(height = 450, width=450, relx=0.2,rely=0.2)\n",
    "\n",
    "        bar1 = FigureCanvasTkAgg(f, self.bargra)\n",
    "        bar1.get_tk_widget().pack(fill=\"both\", expand=False)\n",
    "\n",
    "\n",
    "\n",
    "    def get_statistical_infor(self,parent):\n",
    "        \n",
    "        # Fetches the selected airport types to filter records from merged_dataframe\n",
    "        selected_checkboxes_airport_type=Null_Handling.Null_Values_Handling().return_selected_checkboxes(parent,parent.airport_types)\n",
    "        \n",
    "        # Select rows by selected airport types\n",
    "        parent.df_airports=parent.merged_df[parent.merged_df[\"type_y\"].isin(selected_checkboxes_airport_type)] #String\n",
    "        \n",
    "        # Fetch records where frequency_mhz <=100\n",
    "        if (parent.frequencyVar.get()==\"Frequencies less than 100 mhz\"):\n",
    "            parent.df_airports_mtz = parent.df_airports[parent.df_airports[\"frequency_mhz\"]<=100]\n",
    "            \n",
    "        else:\n",
    "            # Fetch records where frequency_mhz >100\n",
    "            parent.df_airports_mtz = parent.df_airports[parent.df_airports[\"frequency_mhz\"]>100]\n",
    "            \n",
    "        # Calculate mean, median, mode and display results\n",
    "        \n",
    "        print(\"Mean : \",parent.df_airports_mtz[\"frequency_mhz\"].mean())\n",
    "        print(\"Median : \",parent.df_airports_mtz[\"frequency_mhz\"].median())\n",
    "        print(\"Mode : \",parent.df_airports_mtz[\"frequency_mhz\"].mode())\n",
    "\n",
    "        parent.text_box_for_mean_median = tk.Text(parent.extra_frame3,height=7,width = 52)\n",
    "        parent.text_box_for_mean_median.place(relx=0.18,rely=0.48)\n",
    "        \n",
    "        parent.text_box_for_mean_median.insert(1.0,\"Mean : {}\".format(parent.df_airports_mtz[\"frequency_mhz\"].mean()))\n",
    "        parent.text_box_for_mean_median.insert(2.0,\"\\nMedian : {}\".format(parent.df_airports_mtz[\"frequency_mhz\"].median()))\n",
    "        parent.text_box_for_mean_median.insert(3.0,\"\\nMode : {}\".format(parent.df_airports_mtz[\"frequency_mhz\"].mode()))\n",
    "        parent.text_box_for_mean_median.tag_configure(\"center\", justify=\"center\")\n",
    "        parent.text_box_for_mean_median.tag_add(\"center\", 1.0, \"end\")\n",
    "        #parent.text_box_for_mean_median.place(relx=1.5,rely=0.5)\n",
    "        parent.text_box_for_mean_median.config(highlightthickness = 2, borderwidth=0,background='#FFFAFA')\n",
    "     \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
